<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">
<chapter id="job">
  <title>Configuring and Running A Job</title>

  <para>In Chapter 2, the overall architecture design was discussed, using the
  following diagram as a guide:</para>

  <mediaobject>
    <imageobject role="html">
      <imagedata align="center"
                 fileref="images/spring-batch-reference-model.png" scale="80" />
    </imageobject>

    <imageobject role="fo">
      <imagedata align="center"
                 fileref="src/site/docbook/reference/images/spring-batch-reference-model.png"
                 width="75%" />
    </imageobject>
  </mediaobject>

  <para>While the Job object may seem like a simple container for steps, there
  are many configuration options that developers should be aware of.
  Furthermore, there are many considerations for how a
  <classname>Job</classname> will be run and how its meta data will be stored
  during that run. This chapter will explain the various configuration options
  and runtime concerns of a <classname>Job</classname>.</para>

  <section>
    <title>Configuring a Job</title>

    <para>The only current implementation of the <classname>Job</classname>
    interface is <classname>SimpleJob</classname>. Since a
    <classname>Job</classname> is just a simple loop through a list of Steps,
    this implementation should be sufficient for the majority of needs. It has
    only three required dependencies: a name,
    <classname>JobRepository</classname>, and a list of Steps.</para>

    <programlisting>  
  &lt;job id="footballJob"&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>

    <para>The namespace defaults to referencing a repository with an id of
    'jobRepository', which is a sensible default. However, this can be
    overriden explicitely:</para>

    <programlisting> 
  &lt;job id="footballJob" <emphasis role="bold">job-repository="specialRepository"</emphasis>&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>

    <section>
      <title>Restartability</title>

      <para>One key concern when execution a batch job, is what happens when a
      failed job is restarted? A Job is considered to have been 'restarted' if
      the same JobInstance has more than one JobExecution. Ideally, all jobs
      should be able to start up where they left off, but there are scenarios
      where this is not possible. <emphasis role="bold">It is entirely up to
      the developer to ensure that a new instance is always created in this
      scenario</emphasis>. However, Spring Batch does provide some help. If a
      Job should never be restarted, but should always be run as part of a new
      <classname>JobInstance</classname>, then the restartable property may be
      set to 'false':</para>

      <programlisting>  
  &lt;job id="footballJob" <emphasis role="bold">restartable="false"</emphasis>&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>

      <para>To phrase it another way, setting restartable to false means "this
      Job does not support being started again". Restarting a Job that is not
      restartable will cause a <classname>JobRestartException</classname> to
      be thrown:</para>

      <programlisting>  
  Job job = new SimpleJob();
  job.setRestartable(false);

  JobParameters jobParameters = new JobParameters();

  JobExecution firstExecution = jobRepository.createJobExecution(job, jobParameters);
  jobRepository.saveOrUpdate(firstExecution);

  try {
    jobRepository.createJobExecution(job, jobParameters);
    fail();
  }
  catch (JobRestartException e) {
    // expected
  }

</programlisting>

      <para>This snippet of JUnit code shows how attempting to create a
      <classname>JobExecution</classname> the first time for a non restartable
      <classname>job</classname> will cause no issues. However, the second
      attempt will throw a <classname>JobRestartException</classname>.</para>
    </section>

    <section>
      <title>Intercepting Job execution</title>

      <para>During the course of the execution of a
      <classname>Job</classname>, it may be useful to be notified of various
      events in its lifecycle so that custom code may be executed. The
      <classname>SimpleJob</classname> allows for this by calling a
      <classname>JobListener</classname> at the appropriate time:</para>

      <programlisting>  
  public interface JobExecutionListener {

    void beforeJob(JobExecution jobExecution);

    void afterJob(JobExecution jobExecution);

  }

</programlisting>

      <para>Listeners can be added to a <classname>SimpleJob</classname> via
      the setJobListeners property:</para>

      <programlisting>  
  &lt;job id="footballJob"&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
    &lt;listeners&gt;
      &lt;listener class="org.springframework.batch.sample.SampleListener"/&gt;
    &lt;/listeners&gt;
  &lt;/job&gt;

</programlisting>

      <para>It should be noted that afterJob will be called regardless of the
      success or failure of the <classname>Job</classname>. If success or
      failure needs to be determined it can be obtained from the
      <classname>JobExecution</classname>:</para>

      <programlisting>
  void afterJob(JobExecution jobExecution){
    if( jobExecution.getStatus = BatchStatus.COMPLETED ){
      //job success
    }
    else if(jobExecution.getStatus = BatchStatus.FAILED){
      //job failure
    }
  }

</programlisting>
    </section>

    <section>
      <title>JobFactory and Stateful Components in Steps</title>

      <para>Unlike many traditional Spring applications, many of the
      components of a batch application are stateful, the file readers and
      writers are obvious examples. The recommended way to deal with this is
      to create a fresh <classname>ApplicationContext</classname> for each job
      execution. If the <classname>Job</classname> is launched from the
      command line with <classname>CommandLineJobRunner</classname> this is
      trivial. For more complex launching scenarios, where jobs are executed
      in parallel or serially from the same process, some extra steps have to
      be taken to ensure that the <classname>ApplicationContext</classname> is
      refreshed. This is preferable to using prototype scope for the stateful
      beans because then they would not receive lifecycle callbacks from the
      container at the end of use. (e.g. through destroy-method in XML)</para>

      <para>The strategy provided by Spring Batch to deal with this scenario
      is the <classname>JobFactory</classname>, and the samples provide an
      example of a specialized implementation that can load an
      <classname>ApplicationContext</classname> and close it properly when the
      job is finished. A relevant examples is
      <classname>ClassPathXmlApplicationContextJobFactory</classname> and its
      use in the <code>adhoc-job-launcher-context.xml</code> and the
      <code>quartz-job-launcher-context.xml</code>, which can be found in the
      Samples project.</para>
    </section>
  </section>

  <section>
    <title>Configuring a JobRepository</title>

    <para>As described in Chatper 2, the JobRepository is used for basic CRUD
    operations of the various persisted domain objects within Spring Batch,
    such as JobExecution and StepExecution. It is required by many of the
    major framework features, such as the <classname>JobLauncher</classname>,
    <classname>Job</classname>, and <classname>Step</classname>. The batch
    namespace abstract much of the implementation details of the JobRepository
    implementations and their collaborators. However, there are still a few
    configuration options available:</para>

    <programlisting>
  &lt;job-repository id="jobRepository"
    dataSource="dataSource"
    transactionManager="transactionManager"
    isolation-level-for-create="serializable"
    table-prefix="BATCH_"
  /&gt;

</programlisting>

    <para>None of the configuration options listed above are required except
    the id. If they are not set, the defaults shown above will be used. They
    are shown above for awareness purposes.</para>

    <section>
      <title>Transaction Configuration For the JobRepository</title>

      <para>If the namespace is used, transactional advice will be
      automatically created around the repository. This is to ensure that the
      batch meta data, including state that is necessary for restarts after a
      failure, is persisted correctly. The behaviour of the framework is not
      well defined if the repository methods are not transactional. The
      isolation level in the <code>create*</code> method attributes is
      specified separately to ensure that when jobs are launched, if two
      processes are trying to launch the same job at the same time, only one
      will succeed. The default isolation level for that method is
      SERIALIZABLE, which is quite aggressive: READ_COMMITTED would work just
      as well; READ_UNCOMMITTED would be fine if two processes are not likely
      to collide in this way. However, since a call to the
      <classname>create*</classname> method is quite short, it is unlikely
      that the SERIALIZED will cause problems, as long as the database
      platform supports it. However, this can be overriden:</para>

      <para><programlisting>  
  &lt;job-repository id="jobRepository"
    <emphasis role="bold">isolation-level-for-create="ISOLATION_REPEATABLE_READ" /&gt;</emphasis>

</programlisting></para>

      <para>If the namespace or factory beans aren't used then it is also
      essential to configure the transactional behaviour of the repository
      using AOP:</para>

      <para><programlisting>  
  &lt;aop:config&gt;
      &lt;aop:advisor 
           pointcut="execution(* org.springframework.batch.core..*Repository+.*(..))"
      &lt;advice-ref="txAdvice" /&gt;
  &lt;/aop:config&gt;

  &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt;
      &lt;tx:attributes&gt;
          &lt;tx:method name="*" /&gt;
      &lt;/tx:attributes&gt;
  &lt;/tx:advice&gt;

</programlisting></para>

      <para>This fragment can be used as is, with almost no changes. Remember
      also to include the appropiate namespace declarations and to make sure
      spring-tx and spring-aop (or the whole of spring) is on the
      classpath.</para>

      <section>
        <title>Recommendations for Indexing Meta Data Tables</title>

        <para>Spring Batch provides DDL samples for the meta-data tables in
        the Core jar file for several common database platforms. Index
        declarations are not included in that DDL because there are too many
        variations in how users may want to index dependeing on their precise
        platform, local conventions and also the business requirements of how
        the jobs will be operated. The table below provides some indication as
        to which columns are going to be used in a WHERE clause by the Dao
        ipmlementations provided by Spring Batch, and how frequently they
        might be used, so that individual projects can make up their own minds
        about indexing.</para>

        <table>
          <title>Where clauses in SQL statements (exluding primary keys) and
          their approximate frequency of use.</title>

          <tgroup cols="3">
            <tbody>
              <row>
                <entry>Default Table Name</entry>

                <entry>Where Clause</entry>

                <entry>Frequency</entry>
              </row>

              <row>
                <entry>BATCH_JOB_INSTANCE</entry>

                <entry>JOB_NAME = ? and JOB_KEY = ?</entry>

                <entry>Every time a job is launched</entry>
              </row>

              <row>
                <entry>BATCH_JOB_EXECUTION</entry>

                <entry>JOB_INSTANCE_ID = ?</entry>

                <entry>Every time a job is restarted</entry>
              </row>

              <row>
                <entry>BATCH_EXECUTION_CONTEXT</entry>

                <entry>EXECUTION_ID = ? and KEY_NAME = ?</entry>

                <entry>On commit interval, a.k.a. chunk</entry>
              </row>

              <row>
                <entry>BATCH_STEP_EXECUTION</entry>

                <entry>VERSION = ?</entry>

                <entry>On commit interval, a.k.a. chunk (and at start and end
                of step)</entry>
              </row>

              <row>
                <entry>BATCH_STEP_EXECUTION</entry>

                <entry>STEP_NAME = ? and JOB_EXECUTION_ID = ?</entry>

                <entry>Before each step execution</entry>
              </row>
            </tbody>
          </tgroup>
        </table>
      </section>
    </section>

    <section>
      <title>Changing the table prefix</title>

      <para>Another modifiable property of the
      <classname>JobRepository</classname> is the table prefix of the
      meta-data tables. By default they are all prefaced with BATCH_.
      BATCH_JOB_EXECUTION and BATCH_STEP_EXECUTION are two examples. However,
      there are potential reasons to modify this prefix. If the schema names
      needs to be prepended to the table names, or if more than one set of
      meta data tables is needed within the same schema, then the table prefix
      will need to be changed:</para>

      <programlisting>
  &lt;job-repository id="jobRepository"
    <emphasis role="bold">table-prefix="SYSTEM.TEST_"</emphasis>
  /&gt;

</programlisting>

      <para>Given the above changes, every query to the meta data tables will
      be prefixed with "SYSTEM.TEST_". BATCH_JOB_EXECUTION will be referred to
      as SYSTEM.TEST_JOB_EXECUTION.</para>

      <note>
        <para>Only the table prefix is configurable, the table and column
        names are not.</para>
      </note>
    </section>

    <section>
      <title>In-Memory Repository</title>

      <para>There are scenarios in which you may not want to persist your
      domain objects to the database. One reason may be speed, storing domain
      objects at each commit point takes extra time. Another reason may be
      that you just don't need to persist status for a particular job. Spring
      batch provides a solution:</para>

      <programlisting>  &lt;bean id="jobRepository" 
        class="org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean" /&gt;</programlisting>
    </section>
  </section>

  <section>
    <title>Configuring a JobLauncher</title>

    <para>The most basic implementation of the
    <classname>JobLauncher</classname> interface is the SimpleJobLauncher.
    It's only required dependency is a <classname>JobRepository</classname>,
    in order to obtain an execution:</para>

    <programlisting>  &lt;bean id="jobLauncher"
        class="org.springframework.batch.execution.launch.SimpleJobLauncher"&gt;
    &lt;property name="jobRepository" ref="jobRepository" /&gt;
  &lt;/bean&gt;</programlisting>

    <para>Once a <classname>JobExecution</classname> is obtained, it is passed
    to the execute method of <classname>Job</classname>, ultimately returning
    the <classname>JobExecution</classname> to the caller:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center"
                   fileref="images/job-launcher-sequence-sync.png" scale="80"
                   width="66%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/job-launcher-sequence-sync.png"
                   scale="80" width="66%" />
      </imageobject>
    </mediaobject>

    <para>The sequence is straightforward, and works well when launched from a
    scheduler, but causes issues when trying to launch from an HTTP request.
    In this scenario, the launching needs to be done asynchronously, so that
    the <classname>SimpleJobLauncher</classname> returns immediately to it's
    caller. This is because it is not good practice to keep an HTTP request
    open for the amount of time needed by long running processes such as
    batch. An example sequence is below:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center"
                   fileref="images/job-launcher-sequence-async.png" scale="80"
                   width="66%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/job-launcher-sequence-async.png"
                   scale="80" width="66%" />
      </imageobject>
    </mediaobject>

    <para>The <classname>SimpleJobLauncher</classname> can easily be
    configured to allow for this scenario by configuring a
    <classname>TaskExecutor</classname>:</para>

    <programlisting> &lt;bean id="jobLauncher"
        class="org.springframework.batch.execution.launch.SimpleJobLauncher"&gt;
    &lt;property name="jobRepository" ref="jobRepository" /&gt;
    &lt;property name="taskExecutor"&gt;
      &lt;bean class="org.springframework.core.task.SimpleAsyncTaskExecutor" /&gt;
    &lt;/property&gt;
  &lt;/bean&gt;</programlisting>

    <para>Any implementation of the spring <classname>TaskExecutor</classname>
    interface can be used to control how jobs are asynchronously
    executed.</para>
  </section>

  <section>
    <title>Running a Job</title>

    <para>At a minimum, launching a batch job requires two things: the Job to
    be launched and a JobLauncher. Both can be contained within the same
    context or different contexts. For example, if launching a job from the
    command line, a new JVM will be instantiated for each Job, and thus every
    job will have it's own <classname>JobLauncher</classname>. However, if
    running from within a web container within the scope of an
    <classname>HttpRequest</classname>, there will usually be one
    <classname>JobLauncher</classname>, configured for asynchronous job
    launching, that multiple requests will invoke to launch their jobs.</para>

    <section>
      <title>Running Jobs from the Command Line</title>

      <para>For users that want to run their jobs from an enterprise
      scheduler, the command line is the primary interface. This is because
      most schedulers (with the exception of Quartz unless using the
      <classname>NativeJob</classname>) work directly with operating system
      processes, primarily kicked off with shell scripts. There are many ways
      to launch a Java process besides a shell script, such as Perl, Ruby, or
      even 'build tools' such as ant or maven. However, because most people
      are familiar with shell scripts, this example will focus on them.</para>

      <section>
        <title>The CommandLineJobRunner</title>

        <para>Because the script launching the job must kick off a Java
        Virtual Machine, there needs to be a class with a main method to act
        as the primary entry point. Spring Batch provides an implementation
        that serves just this purpose:
        <classname>CommandLineJobRunner</classname>. It's important to note
        that this is just one way to bootstrap your application, but there are
        many ways to launch a Java process, and this class should in no way be
        viewed as definitive. It performs four tasks:</para>

        <itemizedlist>
          <listitem>
            <para>Loads the appropriate Application Context</para>
          </listitem>

          <listitem>
            <para>Parses command line arguments into JobParameters</para>
          </listitem>

          <listitem>
            <para>Locates the appropriate job based on arguments</para>
          </listitem>

          <listitem>
            <para>Uses the JobLauncher provided in the application context to
            launch the job.</para>
          </listitem>
        </itemizedlist>

        <para>All of these tasks are accomplished based completely upon the
        arguments passed in. The following are required arguments:</para>

        <table>
          <title>CommandLineJobRunner arguments</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry>jobPath</entry>

                <entry>The location of the XML file that will be used to
                create an <classname>ApplicationContext</classname>. This file
                should contain everything needed to run the complete
                <classname>Job</classname></entry>
              </row>

              <row>
                <entry>jobName</entry>

                <entry>The name of the job to be run.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>

        <para>These arguments must be passed in with the path first and the
        name second. All arguments after these are considered to be
        JobParameters and must be in the format of 'name=value':</para>

        <screen><prompt>bash$</prompt> java CommandLineJobRunner endOfDayJob.xml endOfDay schedule.date(date)=2008/01/01</screen>

        <para>In most cases you would want to use a manifest to declare your
        main class in a jar, but for simplicity, the class was used directly.
        This example is using the same 'EndOfDay' example from Chapter 2. The
        first argument is 'endOfDayJob.xml', which is the Spring
        <classname>ApplicationContext</classname> containing the Job. The
        second argument, 'endOfDay' represents the job name. The final
        argument, 'schedule.date=01-01-2008' will be converted into
        <classname>JobParameters</classname>. An example of the XML
        configuration is below:</para>

        <programlisting>  &lt;bean id="endOfDay"
        class="org.springframework.batch.core.job.SimpleJob"&gt;
    &lt;property name="steps"&gt;
      &lt;bean id="step1" parent="simpleStep" /&gt;
      &lt;!-- Step details removed for clarity --&gt;
    &lt;/property&gt; 
  &lt;/bean&gt;

  &lt;!-- Launcher details removed for clarity --&gt;
  &lt;bean id="jobLauncher"
        class="org.springframework.batch.core.launch.support.SimpleJobLauncher" /&gt;</programlisting>

        <para>This example is overly simplistic, since there are many more
        requirements to a run a batch job in Spring Batch in general, but it
        serves to show the two main requirements of the
        <classname>CommandLineJobRunner</classname>:
        <classname>Job</classname> and
        <classname>JobLauncher</classname></para>
      </section>

      <section>
        <title>ExitCodes</title>

        <para>When launching a batch job from the command-line, it is often
        from an enterprise scheduler. Most schedulers are fairly dumb, and
        work only at the process level. Meaning, they only know about some
        operating system process such as a shell script that they're invoking.
        In this scenario, the only way to communicate back to the scheduler
        about the success or failure of a job is through return codes. A
        number is returned to a scheduler that is told how to interpret the
        result. In the simple case: 0 is success and 1 is failure. However,
        there may be scenarios such as: If job A returns 4 kick off job B, if
        it returns 5 kick off job C. This type of behavior is configured at
        the scheduler level, but it is important that a processing framework
        such as Spring Batch provide a way to return a numeric representation
        of of the 'Exit Code' for a particular batch job. In Spring Batch this
        is encapsulated within an <classname>ExitStatus</classname>, which is
        covered in more detail in Chapter 5. For the purposes of discussing
        exit codes, the only important thing to know is that an
        <classname>ExitStatus</classname> has an exit code property that is
        set by the framework (or the developer) and is returned as part of the
        <classname>JobExecution</classname> returned from the
        <classname>JobLauncher</classname>. The
        <classname>CommandLineJobRunner</classname> converts this string value
        to a number using the <classname>ExitCodeMapper</classname>
        interface:</para>

        <programlisting>  public interface ExitCodeMapper {

    public int intValue(String exitCode);
}</programlisting>

        <para>The essential contract of an
        <classname>ExitCodeMapper</classname> is that, given a string exit
        code, a number representation will be returned. The default
        implementation used by the job runner is the SimpleJvmExitCodeMapper
        that returns 0 for completion, 1 for generic errors, and 2 for any job
        runner errors such as not being able to find a
        <classname>Job</classname> in the provided context. If anything more
        complex than the 3 values above is needed, then a custom
        implementation of the <classname>ExitCodeMapper</classname> interface
        must be supplied. Because the
        <classname>CommandLineJobRunner</classname> is the class that creates
        an <classname>ApplicationContext</classname>, and thus cannot be
        'wired together', any values that need to be overwritten must be
        autowired. This means that if an implementation of
        <classname>ExitCodeMapper</classname> is found within the BeanFactory,
        it will be injected into the runner after the context is created. All
        that needs to be done to provide your own
        <classname>ExitCodeMapper</classname> is to declare the implementation
        as a root level bean, and ensure it's part of the
        <classname>ApplicationContext</classname> that is loaded by the
        runner.</para>
      </section>
    </section>

    <section>
      <title>Running Jobs from within a container</title>

      <para></para>
    </section>
  </section>

  <section>
    <title>Advanced Meta-Data Usage</title>

    <para></para>

    <section>
      <title>Querying the repository</title>

      <para></para>

      <section>
        <title>JobExporer</title>

        <para></para>
      </section>
    </section>

    <section>
      <title>Stopping a Job</title>

      <para>One of the most common reasons for wanting to launching a
      <classname>job</classname> asynchronously is to be able to gracefully
      stop it. This can be done through the
      <classname>JobExecution</classname> returned by the
      <classname>JobLauncher</classname>:</para>

      <programlisting>  JobExecution jobExecution = launcher.run(getJob(), jobParameters);

  //give job adequate time to start
  Thread.sleep(1000);

  assertEquals(BatchStatus.STARTED, jobExecution.getStatus());
  assertTrue(jobExecution.isRunning());

  jobExecution.stop();

  //give job time to stop
  Thread.sleep(1000);

  assertEquals(BatchStatus.STOPPED, jobExecution.getStatus());
  assertFalse(jobExecution.isRunning());</programlisting>

      <para>The shutdown is not immediate, since there is no way to force
      immediate shutdown, especially if the execution is currently in
      developer code that the framework has no control over, such as a
      business service. What it does mean, is that as soon as control is
      returned back to the framework, it will set the status of the current
      <classname>StepExecution</classname> to
      <classname>BatchStatus.STOPPED</classname>, save it, then do the same
      for the <classname>JobExecution</classname> before finishing.</para>

      <section>
        <title>JobOperator</title>

        <para></para>
      </section>
    </section>
  </section>
</chapter>