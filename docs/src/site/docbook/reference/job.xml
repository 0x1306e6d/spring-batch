<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">
<chapter id="configureJob">
  <title>Configuring and Running A Job</title>

  <para>In <xref linkend="domain" />, the overall architecture design was
  discussed, using the following diagram as a guide:</para>

  <mediaobject>
    <imageobject role="html">
      <imagedata align="center"
                 fileref="images/spring-batch-reference-model.png" scale="80" />
    </imageobject>

    <imageobject role="fo">
      <imagedata align="center"
                 fileref="src/site/docbook/reference/images/spring-batch-reference-model.png"
                 width="75%" />
    </imageobject>
  </mediaobject>

  <para>While the Job object may seem like a simple container for steps, there
  are many configuration options that developers should be aware of.
  Furthermore, there are many considerations for how a
  <classname>Job</classname> will be run and how its meta data will be stored
  during that run. This chapter will explain the various configuration options
  and runtime concerns of a <classname>Job</classname>.</para>

  <section>
    <title>Configuring a Job</title>

    <para>There are multiple implementations of the <link
    linkend="job">Job</link> interface, however, the namespace abstracts away
    the differences in configuration. It has only three required dependencies:
    a name, <classname>JobRepository</classname>, and a list of Steps.</para>

    <programlisting>  
  &lt;job id="footballJob"&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>

    <para>The namespace defaults to referencing a repository with an id of
    'jobRepository', which is a sensible default. However, this can be
    overridden explicitly:</para>

    <programlisting> 
  &lt;job id="footballJob" <emphasis role="bold">job-repository="specialRepository"</emphasis>&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>

    <section>
      <title>Restartability</title>

      <para>One key concern when execution a batch job, is what happens when a
      failed job is restarted? A Job is considered to have been 'restarted' if
      the same <classname>JobInstance</classname> has more than one
      JobExecution. Ideally, all jobs should be able to start up where they
      left off, but there are scenarios where this is not possible. <emphasis
      role="bold">It is entirely up to the developer to ensure that a new
      instance is always created in this scenario</emphasis>. However, Spring
      Batch does provide some help. If a Job should never be restarted, but
      should always be run as part of a new
      <classname>JobInstance</classname>, then the restartable property may be
      set to 'false':</para>

      <programlisting>  
  &lt;job id="footballJob" <emphasis role="bold">restartable="false"</emphasis>&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>

      <para>To phrase it another way, setting restartable to false means "this
      Job does not support being started again". Restarting a Job that is not
      restartable will cause a <classname>JobRestartException</classname> to
      be thrown:</para>

      <programlisting>  
  Job job = new SimpleJob();
  job.setRestartable(false);

  JobParameters jobParameters = new JobParameters();

  JobExecution firstExecution = jobRepository.createJobExecution(job, jobParameters);
  jobRepository.saveOrUpdate(firstExecution);

  try {
    jobRepository.createJobExecution(job, jobParameters);
    fail();
  }
  catch (JobRestartException e) {
    // expected
  }

</programlisting>

      <para>This snippet of JUnit code shows how attempting to create a
      <classname>JobExecution</classname> the first time for a non restartable
      <classname>job</classname> will cause no issues. However, the second
      attempt will throw a <classname>JobRestartException</classname>.</para>
    </section>

    <section>
      <title>Intercepting Job execution</title>

      <para>During the course of the execution of a
      <classname>Job</classname>, it may be useful to be notified of various
      events in its lifecycle so that custom code may be executed. The
      <classname>SimpleJob</classname> allows for this by calling a
      <classname>JobListener</classname> at the appropriate time:</para>

      <programlisting>  
  public interface JobExecutionListener {

    void beforeJob(JobExecution jobExecution);

    void afterJob(JobExecution jobExecution);

  }

</programlisting>

      <para>Listeners can be added to a <classname>SimpleJob</classname> via
      the setJobListeners property:</para>

      <programlisting>  
  &lt;job id="footballJob"&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
    &lt;listeners&gt;
      &lt;listener class="org.springframework.batch.sample.SampleListener"/&gt;
    &lt;/listeners&gt;
  &lt;/job&gt;

</programlisting>

      <para>It should be noted that afterJob will be called regardless of the
      success or failure of the <classname>Job</classname>. If success or
      failure needs to be determined it can be obtained from the
      <classname>JobExecution</classname>:</para>

      <programlisting>
  void afterJob(JobExecution jobExecution){
    if( jobExecution.getStatus = BatchStatus.COMPLETED ){
      //job success
    }
    else if(jobExecution.getStatus = BatchStatus.FAILED){
      //job failure
    }
  }

</programlisting>
    </section>

    <section>
      <title>JobFactory and Stateful Components in Steps</title>

      <para>Unlike many traditional Spring applications, many of the
      components of a batch application are stateful, the file readers and
      writers are obvious examples. The recommended way to deal with this is
      to create a fresh <classname>ApplicationContext</classname> for each job
      execution. If the <classname>Job</classname> is launched from the
      command line with <classname>CommandLineJobRunner</classname> this is
      trivial. For more complex launching scenarios, where jobs are executed
      in parallel or serially from the same process, some extra steps have to
      be taken to ensure that the <classname>ApplicationContext</classname> is
      refreshed. This is preferable to using prototype scope for the stateful
      beans because then they would not receive lifecycle callbacks from the
      container at the end of use. (e.g. through destroy-method in XML)</para>

      <para>The strategy provided by Spring Batch to deal with this scenario
      is the <classname>JobFactory</classname>, and the samples provide an
      example of a specialized implementation that can load an
      <classname>ApplicationContext</classname> and close it properly when the
      job is finished. A relevant examples is
      <classname>ClassPathXmlApplicationContextJobFactory</classname> and its
      use in the <code>adhoc-job-launcher-context.xml</code> and the
      <code>quartz-job-launcher-context.xml</code>, which can be found in the
      Samples project.</para>
    </section>
  </section>

  <section>
    <title>Configuring a JobRepository</title>

    <para>As described in earlier, the <link
    linkend="jobRepository">JobRepository</link> is used for basic CRUD
    operations of the various persisted domain objects within Spring Batch,
    such as JobExecution and StepExecution. It is required by many of the
    major framework features, such as the <classname>JobLauncher</classname>,
    <classname>Job</classname>, and <classname>Step</classname>. The batch
    namespace abstract much of the implementation details of the
    <classname>JobRepository</classname> implementations and their
    collaborators. However, there are still a few configuration options
    available:</para>

    <programlisting>
  &lt;job-repository id="jobRepository"
    dataSource="dataSource"
    transactionManager="transactionManager"
    isolation-level-for-create="serializable"
    table-prefix="BATCH_"
  /&gt;

</programlisting>

    <para>None of the configuration options listed above are required except
    the id. If they are not set, the defaults shown above will be used. They
    are shown above for awareness purposes.</para>

    <section>
      <title>Transaction Configuration For the JobRepository</title>

      <para>If the namespace is used, transactional advice will be
      automatically created around the repository. This is to ensure that the
      batch meta data, including state that is necessary for restarts after a
      failure, is persisted correctly. The behaviour of the framework is not
      well defined if the repository methods are not transactional. The
      isolation level in the <code>create*</code> method attributes is
      specified separately to ensure that when jobs are launched, if two
      processes are trying to launch the same job at the same time, only one
      will succeed. The default isolation level for that method is
      SERIALIZABLE, which is quite aggressive: READ_COMMITTED would work just
      as well; READ_UNCOMMITTED would be fine if two processes are not likely
      to collide in this way. However, since a call to the
      <classname>create*</classname> method is quite short, it is unlikely
      that the SERIALIZED will cause problems, as long as the database
      platform supports it. However, this can be overridden:</para>

      <para><programlisting>  
  &lt;job-repository id="jobRepository"
    <emphasis role="bold">isolation-level-for-create="ISOLATION_REPEATABLE_READ" /&gt;</emphasis>

</programlisting></para>

      <para>If the namespace or factory beans aren't used then it is also
      essential to configure the transactional behaviour of the repository
      using AOP:</para>

      <para><programlisting>  
  &lt;aop:config&gt;
      &lt;aop:advisor 
           pointcut="execution(* org.springframework.batch.core..*Repository+.*(..))"
      &lt;advice-ref="txAdvice" /&gt;
  &lt;/aop:config&gt;

  &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt;
      &lt;tx:attributes&gt;
          &lt;tx:method name="*" /&gt;
      &lt;/tx:attributes&gt;
  &lt;/tx:advice&gt;

</programlisting></para>

      <para>This fragment can be used as is, with almost no changes. Remember
      also to include the appropriate namespace declarations and to make sure
      spring-tx and spring-aop (or the whole of spring) is on the
      classpath.</para>
    </section>

    <section id="repositoryTablePrefix">
      <title>Changing the table prefix</title>

      <para>Another modifiable property of the
      <classname>JobRepository</classname> is the table prefix of the
      meta-data tables. By default they are all prefaced with BATCH_.
      BATCH_JOB_EXECUTION and BATCH_STEP_EXECUTION are two examples. However,
      there are potential reasons to modify this prefix. If the schema names
      needs to be prepended to the table names, or if more than one set of
      meta data tables is needed within the same schema, then the table prefix
      will need to be changed:</para>

      <programlisting>
  &lt;job-repository id="jobRepository"
    <emphasis role="bold">table-prefix="SYSTEM.TEST_"</emphasis>
  /&gt;

</programlisting>

      <para>Given the above changes, every query to the meta data tables will
      be prefixed with "SYSTEM.TEST_". BATCH_JOB_EXECUTION will be referred to
      as SYSTEM.TEST_JOB_EXECUTION.</para>

      <note>
        <para>Only the table prefix is configurable, the table and column
        names are not.</para>
      </note>
    </section>

    <section>
      <title>In-Memory Repository</title>

      <para>There are scenarios in which you may not want to persist your
      domain objects to the database. One reason may be speed, storing domain
      objects at each commit point takes extra time. Another reason may be
      that you just don't need to persist status for a particular job. Spring
      batch provides a solution:</para>

      <programlisting>  &lt;bean id="jobRepository" 
        class="org.springframework.batch.core.repository.support.MapJobRepositoryFactoryBean" /&gt;</programlisting>
    </section>
  </section>

  <section>
    <title>Configuring a JobLauncher</title>

    <para>The most basic implementation of the
    <classname>JobLauncher</classname> interface is the
    <classname>SimpleJobLauncher</classname>. It's only required dependency is
    a <classname>JobRepository</classname>, in order to obtain an
    execution:</para>

    <programlisting>  &lt;bean id="jobLauncher"
        class="org.springframework.batch.execution.launch.SimpleJobLauncher"&gt;
    &lt;property name="jobRepository" ref="jobRepository" /&gt;
  &lt;/bean&gt;</programlisting>

    <para>Once a <link linkend="jobExecution">JobExecution</link> is obtained,
    it is passed to the execute method of <classname>Job</classname>,
    ultimately returning the <classname>JobExecution</classname> to the
    caller:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center"
                   fileref="images/job-launcher-sequence-sync.png" scale="80"
                   width="66%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/job-launcher-sequence-sync.png"
                   scale="80" width="66%" />
      </imageobject>
    </mediaobject>

    <para>The sequence is straightforward, and works well when launched from a
    scheduler, but causes issues when trying to launch from an HTTP request.
    In this scenario, the launching needs to be done asynchronously, so that
    the <classname>SimpleJobLauncher</classname> returns immediately to it's
    caller. This is because it is not good practice to keep an HTTP request
    open for the amount of time needed by long running processes such as
    batch. An example sequence is below:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center"
                   fileref="images/job-launcher-sequence-async.png" scale="80"
                   width="66%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/job-launcher-sequence-async.png"
                   scale="80" width="66%" />
      </imageobject>
    </mediaobject>

    <para>The <classname>SimpleJobLauncher</classname> can easily be
    configured to allow for this scenario by configuring a
    <classname>TaskExecutor</classname>:</para>

    <programlisting> &lt;bean id="jobLauncher"
        class="org.springframework.batch.execution.launch.SimpleJobLauncher"&gt;
    &lt;property name="jobRepository" ref="jobRepository" /&gt;
    &lt;property name="taskExecutor"&gt;
      &lt;bean class="org.springframework.core.task.SimpleAsyncTaskExecutor" /&gt;
    &lt;/property&gt;
  &lt;/bean&gt;</programlisting>

    <para>Any implementation of the spring <classname>TaskExecutor</classname>
    interface can be used to control how jobs are asynchronously
    executed.</para>
  </section>

  <section>
    <title>Running a Job</title>

    <para>At a minimum, launching a batch job requires two things: the Job to
    be launched and a <classname>JobLauncher</classname>. Both can be
    contained within the same context or different contexts. For example, if
    launching a job from the command line, a new JVM will be instantiated for
    each Job, and thus every job will have it's own
    <classname>JobLauncher</classname>. However, if running from within a web
    container within the scope of an <classname>HttpRequest</classname>, there
    will usually be one <classname>JobLauncher</classname>, configured for
    asynchronous job launching, that multiple requests will invoke to launch
    their jobs.</para>

    <section>
      <title>Running Jobs from the Command Line</title>

      <para>For users that want to run their jobs from an enterprise
      scheduler, the command line is the primary interface. This is because
      most schedulers (with the exception of Quartz unless using the
      <classname>NativeJob</classname>) work directly with operating system
      processes, primarily kicked off with shell scripts. There are many ways
      to launch a Java process besides a shell script, such as Perl, Ruby, or
      even 'build tools' such as ant or maven. However, because most people
      are familiar with shell scripts, this example will focus on them.</para>

      <section>
        <title>The CommandLineJobRunner</title>

        <para>Because the script launching the job must kick off a Java
        Virtual Machine, there needs to be a class with a main method to act
        as the primary entry point. Spring Batch provides an implementation
        that serves just this purpose:
        <classname>CommandLineJobRunner</classname>. It's important to note
        that this is just one way to bootstrap your application, but there are
        many ways to launch a Java process, and this class should in no way be
        viewed as definitive. It performs four tasks:</para>

        <itemizedlist>
          <listitem>
            <para>Loads the appropriate Application Context</para>
          </listitem>

          <listitem>
            <para>Parses command line arguments into JobParameters</para>
          </listitem>

          <listitem>
            <para>Locates the appropriate job based on arguments</para>
          </listitem>

          <listitem>
            <para>Uses the JobLauncher provided in the application context to
            launch the job.</para>
          </listitem>
        </itemizedlist>

        <para>All of these tasks are accomplished based completely upon the
        arguments passed in. The following are required arguments:</para>

        <table>
          <title>CommandLineJobRunner arguments</title>

          <tgroup cols="2">
            <tbody>
              <row>
                <entry>jobPath</entry>

                <entry>The location of the XML file that will be used to
                create an <classname>ApplicationContext</classname>. This file
                should contain everything needed to run the complete
                <classname>Job</classname></entry>
              </row>

              <row>
                <entry>jobName</entry>

                <entry>The name of the job to be run.</entry>
              </row>
            </tbody>
          </tgroup>
        </table>

        <para>These arguments must be passed in with the path first and the
        name second. All arguments after these are considered to be
        JobParameters and must be in the format of 'name=value':</para>

        <screen><prompt>bash$</prompt> java CommandLineJobRunner endOfDayJob.xml endOfDay schedule.date(date)=2008/01/01</screen>

        <para>In most cases you would want to use a manifest to declare your
        main class in a jar, but for simplicity, the class was used directly.
        This example is using the same 'EndOfDay' example from <xref
        linkend="domain" />. The first argument is 'endOfDayJob.xml', which is
        the Spring <classname>ApplicationContext</classname> containing the
        Job. The second argument, 'endOfDay' represents the job name. The
        final argument, 'schedule.date=01-01-2008' will be converted into
        <classname>JobParameters</classname>. An example of the XML
        configuration is below:</para>

        <programlisting>  &lt;bean id="endOfDay"
        class="org.springframework.batch.core.job.SimpleJob"&gt;
    &lt;property name="steps"&gt;
      &lt;bean id="step1" parent="simpleStep" /&gt;
      &lt;!-- Step details removed for clarity --&gt;
    &lt;/property&gt; 
  &lt;/bean&gt;

  &lt;!-- Launcher details removed for clarity --&gt;
  &lt;bean id="jobLauncher"
        class="org.springframework.batch.core.launch.support.SimpleJobLauncher" /&gt;</programlisting>

        <para>This example is overly simplistic, since there are many more
        requirements to a run a batch job in Spring Batch in general, but it
        serves to show the two main requirements of the
        <classname>CommandLineJobRunner</classname>:
        <classname>Job</classname> and
        <classname>JobLauncher</classname></para>
      </section>

      <section>
        <title>ExitCodes</title>

        <para>When launching a batch job from the command-line, it is often
        from an enterprise scheduler. Most schedulers are fairly dumb, and
        work only at the process level. Meaning, they only know about some
        operating system process such as a shell script that they're invoking.
        In this scenario, the only way to communicate back to the scheduler
        about the success or failure of a job is through return codes. A
        number is returned to a scheduler that is told how to interpret the
        result. In the simple case: 0 is success and 1 is failure. However,
        there may be scenarios such as: If job A returns 4 kick off job B, if
        it returns 5 kick off job C. This type of behavior is configured at
        the scheduler level, but it is important that a processing framework
        such as Spring Batch provide a way to return a numeric representation
        of of the 'Exit Code' for a particular batch job. In Spring Batch this
        is encapsulated within an <classname>ExitStatus</classname>, which is
        covered in more detail in Chapter 5. For the purposes of discussing
        exit codes, the only important thing to know is that an
        <classname>ExitStatus</classname> has an exit code property that is
        set by the framework (or the developer) and is returned as part of the
        <classname>JobExecution</classname> returned from the
        <classname>JobLauncher</classname>. The
        <classname>CommandLineJobRunner</classname> converts this string value
        to a number using the <classname>ExitCodeMapper</classname>
        interface:</para>

        <programlisting>  public interface ExitCodeMapper {

    public int intValue(String exitCode);
}</programlisting>

        <para>The essential contract of an
        <classname>ExitCodeMapper</classname> is that, given a string exit
        code, a number representation will be returned. The default
        implementation used by the job runner is the SimpleJvmExitCodeMapper
        that returns 0 for completion, 1 for generic errors, and 2 for any job
        runner errors such as not being able to find a
        <classname>Job</classname> in the provided context. If anything more
        complex than the 3 values above is needed, then a custom
        implementation of the <classname>ExitCodeMapper</classname> interface
        must be supplied. Because the
        <classname>CommandLineJobRunner</classname> is the class that creates
        an <classname>ApplicationContext</classname>, and thus cannot be
        'wired together', any values that need to be overwritten must be
        autowired. This means that if an implementation of
        <classname>ExitCodeMapper</classname> is found within the BeanFactory,
        it will be injected into the runner after the context is created. All
        that needs to be done to provide your own
        <classname>ExitCodeMapper</classname> is to declare the implementation
        as a root level bean, and ensure it's part of the
        <classname>ApplicationContext</classname> that is loaded by the
        runner.</para>
      </section>
    </section>

    <section>
      <title>Running Jobs from within a container</title>

      <para></para>
    </section>
  </section>

  <section id="advancedMetaData">
    <title>Advanced Meta-Data Usage</title>

    <para>So far, both the JobLauncher and JobRepository interfaces have been
    discussed. Together, they represent simple launching of a job, and basic
    CRUD operations of batch domain objects:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center" fileref="images/job-repository.png" scale=""
                   width="40%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/job-repository.png"
                   scale="80" width="40%" />
      </imageobject>
    </mediaobject>

    <para>A <classname>JobLauncher</classname> uses the
    <classname>JobRepository</classname> to create new
    <classname>JobExecution</classname> objects, and run them.
    <classname>Job</classname> and <classname>Step</classname> implementations
    later use the same <classname>JobRepository</classname> for basic updates
    of the same executions during the running of a <classname>Job</classname>.
    The basic operations suffice for simple scenarios. However, in a large
    batch environment with hundreds of batch jobs and complex scheduling
    requirements, more advanced access of the meta data is required:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center" fileref="images/job-repository-advanced.png"
                   scale="" width="65%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/job-repository-advanced.png"
                   scale="80" width="65%" />
      </imageobject>
    </mediaobject>

    <para>The <classname>JobExplorer</classname> and
    <classname>JobOperator</classname> interfaces, which will be discussed
    below, add additional functionality for querying and controlling the meta
    data.</para>

    <section>
      <title>Querying the repository</title>

      <para>The most basic need before any advanced features is the ability to
      query the repository for existing executions. This functionality is
      provided by the <classname>JobExplorer</classname> interface:</para>

      <programlisting>  
  public interface JobExplorer {

    List&lt;JobInstance&gt; getJobInstances(String jobName, int start, int count);

    JobExecution getJobExecution(Long executionId);

    StepExecution getStepExecution(Long jobExecutionId, Long stepExecutionId);

    JobInstance getJobInstance(Long instanceId);

    List&lt;JobExecution&gt; getJobExecutions(JobInstance jobInstance);

    Set&lt;JobExecution&gt; findRunningJobExecutions(String jobName);
  }

</programlisting>

      <para>As is evident from the method signatures above,
      <classname>JobExplorer</classname> is a read-only version of the
      <classname>JobRepository</classname>, and like the
      <classname>JobRepository</classname>, it can be easily configured via a
      factory bean:</para>

      <programlisting>  
  &lt;bean id="jobExplorer" class="org.springframework.batch.core.explore.support.JobExplorerFactoryBean" 
        p:dataSource-ref="dataSource" /&gt;

</programlisting>

      <para><link linkend="repositoryTablePrefix">Earlier in this
      chapter</link>, it was mentioned that the table prefix of the
      JobRepository can be modified to allow for different versions or
      schemas. Because the JobExplorer is working with the same tables, it too
      needs the ability to set a prefix:</para>

      <programlisting>  
  &lt;bean id="jobExplorer" class="org.springframework.batch.core.explore.support.JobExplorerFactoryBean" 
        p:dataSource-ref="dataSource" <emphasis role="bold">p:tablePrefix="BATCH_" </emphasis>/&gt;

</programlisting>
    </section>

    <section>
      <title>JobOperator</title>

      <para>As previously discussed, the <classname>JobRepository</classname>
      provides CRUD operations on the meta-data, and the
      <classname>JobExplorer</classname> provides read-only operations on the
      meta-data. However, those operations are most useful when used together
      to perform common monitoring tasks such as stopping, restarting, or
      summarizing a Job, as is commonly done by batch operators. Spring Batch
      provides for these types of operations via the
      <classname>JobOperator</classname> interface:</para>

      <programlisting>
  public interface JobOperator {

    List&lt;Long&gt; getExecutions(long instanceId) throws NoSuchJobInstanceException;

    List&lt;Long&gt; getJobInstances(String jobName, int start, int count) throws NoSuchJobException;

    Set&lt;Long&gt; getRunningExecutions(String jobName) throws NoSuchJobException;

    String getParameters(long executionId) throws NoSuchJobExecutionException;

    Long start(String jobName, String parameters) 
           throws NoSuchJobException, JobInstanceAlreadyExistsException;

    Long restart(long executionId) 
           throws JobInstanceAlreadyCompleteException, NoSuchJobExecutionException,
                  NoSuchJobException, JobRestartException;

    Long startNextInstance(String jobName) 
           throws NoSuchJobException, JobParametersNotFoundException, JobRestartException, 
                  JobExecutionAlreadyRunningException, JobInstanceAlreadyCompleteException;

    boolean stop(long executionId) throws NoSuchJobExecutionException, JobExecutionNotRunningException;

    String getSummary(long executionId) throws NoSuchJobExecutionException;

    Map&lt;Long, String&gt; getStepExecutionSummaries(long executionId) throws NoSuchJobExecutionException;

    Set&lt;String&gt; getJobNames();

  }

</programlisting>

      <para>The above operations represent methods from many different
      interfaces, such as <classname>JobLauncher</classname>,
      <classname>JobRepository</classname>,
      <classname>JobExplorer</classname>, and
      <classname>JobRegistry</classname>. For this reason, the provided
      implementation of <classname>JobOperator</classname>,
      <classname>SimpleJobOperator</classname>, has many dependencies:</para>

      <programlisting>
  &lt;bean id="jobOperator" class="org.springframework.batch.core.launch.support.SimpleJobOperator"&gt;
    &lt;property name="jobExplorer"&gt;
      &lt;bean class="org.springframework.batch.core.explore.support.JobExplorerFactoryBean"&gt;
        &lt;property name="dataSource" ref="dataSource" /&gt;
      &lt;/bean&gt; 
    &lt;/property&gt;
    &lt;property name="jobRepository" ref="jobRepository" /&gt;
    &lt;property name="jobRegistry" ref="jobRegistry" /&gt;
    &lt;property name="jobLauncher" ref="jobLauncher" /&gt;
  &lt;/bean&gt;

</programlisting>
    </section>

    <section>
      <title>JobParametersIncrementer</title>

      <para>Most of the methods on <classname>JobOperator</classname> are
      self-explanatory, and more detailed explanations can be found on the
      <ulink
      url="http://static.springframework.org/spring-batch/apidocs/org/springframework/batch/core/launch/JobOperator.html">javadoc
      of the interface</ulink>. However, the 'startNextInstance' method is
      worth noting. This method will always start a new instance of a Job.
      This can be extremely useful if there are serious issues in a
      <classname>Job</classname>Execution, and the <classname>Job</classname>
      needs to be started over again from the beginning. Unlike
      <classname>JobLauncher</classname> though, which requires a new
      <classname>JobParameters</classname> that will trigger a new JobInstance
      if they are different than any previous one, the startNextInstance
      method will use the JobParametersIncrementer tied to the Job to force
      the <classname>Job</classname> to a new instance:</para>

      <programlisting>
  public interface JobParametersIncrementer {

    JobParameters getNext(JobParameters parameters);
  }

</programlisting>

      <para>The contract of <classname>JobParametersIncrementer</classname> is
      that, given a <link linkend="jobParameters">JobParameters</link>, it
      will return the 'next' parameter by incrementing any values it may
      contain. This strategy is useful because the framework has no way of
      knowing what changes to the JobParameters make it the 'next' instance.
      For example, if the only value in JobParameters is a date, and the next
      instance should be created, should that value be incremented by one day?
      Or one week? (if the job is weekly for instance) The same can be said
      for any numerical values that help to identify the Job, as shown
      below:</para>

      <programlisting>  
  public class SampleIncrementer implements JobParametersIncrementer {
  
    public JobParameters getNext(JobParameters parameters) { 
      if (parameters==null || parameters.isEmpty()) {
        return new JobParametersBuilder().addLong("run.id", 1L).toJobParameters();
      }
      long id = parameters.getLong("run.id",1L) + 1;
      return new JobParametersBuilder().addLong("run.id", id).toJobParameters();
    }
}

</programlisting>

      <para>In this example, the value with a key of 'run.id' is used to
      discriminate between JobInstances. If the JobParameters passed in is
      null, it can be assumed that the Job has never been run before and thus
      it's initial state can be returned. However, if not, the old value is
      obtained, incremented by one, and returned. An incrementer can be
      associated with Job via the 'incrementer' attribute in the
      namespace:</para>

      <programlisting>  
  &lt;job id="footballJob" <emphasis role="bold">incrementer="sampleIncrementer"</emphasis>&gt;
    &lt;step name="playerload" next="gameLoad"/&gt;
    &lt;step name="gameLoad" next="playerSummarization"/&gt;
    &lt;step name="playerSummarization"/&gt;
  &lt;/job&gt;

</programlisting>
    </section>

    <section>
      <title>Stopping a Job</title>

      <para>One of the most common use cases of
      <classname>JobOperator</classname> is gracefully stopping a
      <classname>Job:</classname></para>

      <programlisting>
  Set&lt;Long&gt; executions = jobOperator.getRunningExecutions("sampleJob");

  jobOperator.stop(executions.iterator().next());
  </programlisting>

      <para>The shutdown is not immediate, since there is no way to force
      immediate shutdown, especially if the execution is currently in
      developer code that the framework has no control over, such as a
      business service. What it does mean, is that as soon as control is
      returned back to the framework, it will set the status of the current
      <classname>StepExecution</classname> to
      <classname>BatchStatus.STOPPED</classname>, save it, then do the same
      for the <classname>JobExecution</classname> before finishing.</para>
    </section>
  </section>
</chapter>
