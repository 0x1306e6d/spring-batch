<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">
<chapter id="patterns">
  <title>Common Batch Patterns</title>

  <para>Some batch jobs can be assembled purely from off-the-shelf components
  in Spring Batch. For instance the <classname>ItemReader</classname> and
  <classname>ItemWriter</classname> implementations can be configured to cover
  a wide range of scenarios. However, for the majority of cases, custom code
  will have to be written. The main API entry points for application
  developers are the <classname>Tasklet</classname>,
  <classname>ItemReader</classname>, <classname>ItemWriter</classname> and the
  various listener interfaces. Most simple batch jobs will be able to use
  off-the-shelf input from a Spring Batch <classname>ItemReader</classname>,
  but it is often the case that there are custom concerns in the processing
  and writing, which require developers to implement an
  <classname>ItemWriter</classname> or
  <classname>ItemProcessor</classname>.</para>

  <para>Here, we provide a few examples of common patterns in custom business
  logic. These examples primarily feature the listener interfaces. It should
  be noted that an <classname>ItemReader</classname> or
  <classname>ItemWriter</classname> can implement a listener interface as
  well, if appropriate.</para>

  <section>
    <title>Logging Item Processing and Failures</title>

    <para>A common use case is the need for special handling of errors in a
    step, item by item, perhaps logging to a special channel, or inserting a
    record into a database. A chunk-oriented <classname>Step</classname>
    (created from the step factory beans) allows users to implement this use
    case with a simple <classname>ItemReadListener</classname>, for errors on
    read, and an <classname>ItemWriteListener</classname>, for errors on
    write. The below code snippets illustrate a listener that logs both read
    and write failures:</para>

    <programlisting>public class ItemFailureLoggerListener extends ItemListenerSupport {

    private static Log logger = LogFactory.getLog("item.error");    

    public void onReadError(Exception ex) {
        logger.error("Encountered error on read", e);
    }

    public void onWriteError(Exception ex, Object item) {
        logger.error("Encountered error on write", e);
    }

}</programlisting>

    <para>Having implemented this listener it must be registered with the
    step:</para>

    <programlisting>&lt;bean id="simpleStep"
        class="org.springframework.batch.core.step.item.SimpleStepFactoryBean" &gt;
    ...
    &lt;property name="listeners"&gt;
        &lt;bean class="org.example...ItemFailureLoggerListener"/&gt;
    &lt;/property&gt;
  &lt;/bean&gt;</programlisting>

    <para>Remember that if your listener does anything in an
    <code>onError()</code> method, it will be inside a transaction that is
    going to be rolled back. If you need to use a transactional resource such
    as a database inside an <code>onError()</code> method, consider adding a
    declarative transaction to that method (see Spring Core Reference Guide
    for details), and giving its propagation attribute the value
    REQUIRES_NEW.</para>
  </section>

  <section>
    <title>Stopping a Job Manually for Business Reasons</title>

    <para>Spring Batch provides a <methodname>stop</methodname>() method
    through the <classname>JobLauncher</classname> interface, but this is
    really for use by the operator rather than the application programmer.
    Sometimes it is more convenient or makes more sense to stop a job
    execution from within the business logic.</para>

    <para>The simplest thing to do is to throw a
    <classname>RuntimeException</classname> (one that isn't retried
    indefinitely or skipped). For example, a custom exception type could be
    used, as in the example below:</para>

    <programlisting>public class PoisonPillItemWriter implements ItemWriter&lt;T&gt; {
    
    public void write(T item) throws Exception {

        if (isPoisonPill(item)) {
            throw new PoisonPillException("Posion pill detected: "+item);
       }

    }

}</programlisting>

    <para>Another simple way to stop a step from executing is to simply return
    <code>null</code> from the <classname>ItemReader</classname>:</para>

    <programlisting>public class EarlyCompletionItemReader implements ItemReader&lt;T&gt; {

    private ItemReader&lt;T&gt; delegate;

    public void setDelegate(ItemReader&lt;T&gt; delegate) { ... }
    
    public T read() throws Exception {

        T item = delegate.read();

        if (isEndItem(item)) {
            return null; // end the step here
        }

        return item;

    }

}</programlisting>

    <para>The previous example actually relies on the fact that there is a
    default implementation of the <classname>CompletionPolicy</classname>
    strategy which signals a complete batch when the item to be processed is
    null. A more sophisticated completion policy could be implemented and
    injected into the <classname>Step</classname> through the
    <classname>RepeatOperationsStepFactoryBean</classname>:</para>

    <programlisting>&lt;bean id="simpleStep"
        class="org.springframework.batch.core.step.item.RepeatOperationsStepFactoryBean" &gt;
    ...
    &lt;property name="chunkOperations"&gt;
        &lt;bean class="org.springframework.batch.repeat.support.RepeatTemplate"&gt;
            &lt;property name="completionPolicy"&gt;
                &lt;bean class="org.example...SpecialCompletionPolicy"/&gt;
            &lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
  &lt;/bean&gt;</programlisting>

    <para>An alternative is to set a flag in the
    <classname>StepExecution</classname>, which is checked by the
    <classname>Step</classname> implementations in the framework in between
    item processing. To implement this alternative, we need access to the
    current <classname>StepExecution</classname>, and this can be achieved by
    implementing a <classname>StepListener</classname> and registering it with
    the <classname>Step</classname>. Here is an example of a listener that
    sets the flag:</para>

    <programlisting>public class CustomItemWriter extends ItemListenerSupport implements StepListener {

    private StepExecution stepExecution;    

    public void beforeStep(StepExecution stepExecution) {
        this.stepExecution = stepExecution;
    }

    public void afterRead(Object item) {

        if (isPoisonPill(item)) {
            stepExecution.setTerminateOnly(true);
       }

    }

}</programlisting>

    <para>The default behavior here when the flag is set is for the step to
    throw a <classname>JobInterruptedException</classname>. This can be
    controlled through the <classname>StepInterruptionPolicy</classname>, but
    the only choice is to throw or not throw an exception, so this is always
    an abnormal ending to a job.</para>
  </section>

  <section>
    <title>Adding a Footer Record</title>

    <para>A very common requirement is to aggregate information during the
    output process and to append a record at the end of a file summarizing the
    data, or providing a checksum. This can also be achieved with a callback
    in the step, normally as part of a custom
    <classname>ItemWriter</classname>. In this case, since a job is
    accumulating state that should not be lost if the job aborts, the
    <classname>ItemStream</classname> interface should be implemented:</para>

    <programlisting>public class CustomItemWriter implements ItemWriter&lt;Trade&gt;,
    ItemStream, StepListener
{

    private static final String TOTAL_AMOUNT_KEY = "total.amount";

    private ItemWriter delegate;

    private double totalAmount = 0.0;

    public void setDelegate(ItemWriter delegate) { ... }

    public ExitStatus afterStep(StepExecution stepExecution) {
        // Add the footer record here...
        delegate.write("Total Amount Processed: " + totalAmount);
    }

    public void open(ExecutionContext executionContext) {
        if (executionContext.containsKey(TOTAL_AMOUNT_KEY) {
            totalAmount = executionContext.getDouble(TOTAL_AMOUNT_KEY);
        }
    }

    public void update(ExecutionContext executionContext) {
        executionContext.setDouble(TOTAL_AMOUNT_KEY, totalAmount);
    }
    
    public void write(Trade item) {
        delegate.write(item);
        totalAmount += item.getAmount();
    }

}</programlisting>

    <para>The custom writer in the example is stateful (it maintains its total
    in an instance variable <varname>totalAmount</varname>), but the state is
    stored through the <classname>ItemStream</classname> interface in the
    <classname>ExecutionContext</classname>. In this way we can be sure that
    when the <code>open()</code> callback is received on a restart. The
    framework garuntees we always get the last value that was committed. It
    should be noted that it is not always necessary to implement
    <classname>ItemStream</classname>. For example, if the
    <classname>ItemWriter</classname> is re-runnable, in the sense that it
    maintains its own state in a transactional resource like a database, there
    is no need to maintain state within the writer itself.</para>
  </section>

  <section>
    <title>Driving Query Based ItemReaders</title>

    <para>In the chapter on readers and writers, database input using paging
    was discussed. Many database vendors, such as DB2, have extremely
    pessimistic locking strategies that can cause issues if the table being
    read also needs to be used by other portions of the online application.
    Furthermore, opening cursors over extremely large datasets can cause
    issues on certain vendors. Therefore, many projects prefer to use a
    'Driving Query' approach to reading in data. This approach works by
    iterating over keys, rather than the entire object that needs to be
    returned, as the following example illustrates:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center" fileref="images/drivingQueryExample.png"
                   width="50%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/drivingQueryExample.png"
                   width="66%" />
      </imageobject>
    </mediaobject>

    <para>As you can see, this example uses the same 'FOO' table as was used
    in the cursor based example. However, rather than selecting the entire
    row, only the ID's were selected in the SQL statement. So, rather than a
    FOO object being returned from <classname>read</classname>, an Integer
    will be returned. This number can then be used to query for the 'details',
    which is a complete Foo object:</para>

    <mediaobject>
      <imageobject role="html">
        <imagedata align="center" fileref="images/drivingQueryJob.png"
                   width="66%" />
      </imageobject>

      <imageobject role="fo">
        <imagedata align="center"
                   fileref="src/site/docbook/reference/images/drivingQueryJob.png"
                   width="66%" />
      </imageobject>
    </mediaobject>

    <para>An ItemProcessor should be used to transform the key obtained from
    the driving query into a full 'Foo' object. An existing DAO can be used to
    query for the full object based on the key.</para>
  </section>

  <section id="multiLineRecords">
    <title>Multi-Line Records</title>

    <para>While it is usually the case with flat files that one each record is
    confined to a single line, it is common that a file might have records
    spanning multiple lines with multiple formats. The following excerpt from
    a file illustrates this:</para>

    <programlisting>  HEA;0013100345;2007-02-15
  NCU;Smith;Peter;;T;20014539;F
  BAD;;Oak Street 31/A;;Small Town;00235;IL;US
  FOT;2;2;267.34</programlisting>

    <para>Everything between the line starting with 'HEA' and the line
    starting with 'FOT' is considered one record. There are a few
    considerations that must be made in order to handle this situation
    correctly:</para>

    <itemizedlist>
      <listitem>
        <para>Instead of reading one record at a time, the
        <classname>ItemReader</classname> must read every line of the
        multi-line record as a group, so that it can be passed to the
        <classname>ItemWriter</classname> intact.</para>
      </listitem>

      <listitem>
        <para>Each line type may need to be tokenized differently.</para>
      </listitem>
    </itemizedlist>

    <para>Because a single record spans multiple lines, and we may not know
    how many lines there are, the <classname>ItemReader</classname> must be
    careful to always read an entire record. In order to do this, a custom
    <classname>ItemReader</classname> should be implemented as a wrapper for
    the <classname>FlatFileItemReader</classname>.</para>

    <programlisting>  &lt;bean id="itemReader" 
        class="org.springframework.batch.sample.iosample.internal.MultiLineTradeItemReader"&gt;
    &lt;property name="delegate"&gt;
      &lt;bean class="org.springframework.batch.item.file.FlatFileItemReader"&gt;
        &lt;property name="resource" value="data/iosample/input/multiLine.txt" /&gt;
        &lt;property name="lineMapper"&gt;
          &lt;bean class="org.springframework.batch.item.file.mapping.DefaultLineMapper"&gt;
            &lt;property name="lineTokenizer" ref="orderFileTokenizer"/&gt;
            &lt;property name="fieldSetMapper"&gt;
              &lt;bean class="org.springframework.batch.item.file.mapping.PassThroughFieldSetMapper" /&gt;
            &lt;/property&gt;
          &lt;/bean&gt;
        &lt;/property&gt;
      &lt;/bean&gt;
    &lt;/property&gt;
  &lt;/bean&gt;</programlisting>

    <para>To ensure that each line is tokenized properly, which is especially
    important for fixed length input, the
    <classname>PrefixMatchingCompositeLineTokenizer</classname> can be used on
    the delegate <classname>FlatFileItemReader</classname>. See <xref
    linkend="prefixMatchingLineMapper" /> for more details. The delegate
    reader will then use a <classname>PassThroughFieldSetMapper</classname> to
    deliver a <classname>FieldSet</classname> for each line back to the
    wrapping <classname>ItemReader</classname>.</para>

    <programlisting>  &lt;bean id="orderFileTokenizer"
        class="org.springframework.batch.io.file.transform.PrefixMatchingCompositeLineTokenizer"&gt;
    &lt;property name="tokenizers"&gt;
      &lt;map&gt;
        &lt;entry key="HEA" value-ref="headerRecordTokenizer" /&gt;
        &lt;entry key="FOT" value-ref="footerRecordTokenizer" /&gt;
        &lt;entry key="NCU" value-ref="customerLineTokenizer" /&gt;
        &lt;entry key="BAD" value-ref="billingAddressLineTokenizer" /&gt;
      &lt;/map&gt;
    &lt;/property&gt;
  &lt;/bean&gt;</programlisting>

    <para>This wrapper will have to be able recognize the end of a record so
    that it can continually call <methodname>read()</methodname> on its
    delegate until the end is reached. For each line that is read, the wrapper
    should build up the item to be returned. Once the footer is reached, the
    item can be returned for delivery to the
    <classname>ItemProcessor</classname> and
    <classname>ItemWriter</classname>.</para>

    <programlisting>  private FlatFileItemReader&lt;FieldSet&gt; delegate;

  public Trade read() throws Exception {
    Trade t = null;

    for (FieldSet line = null; (line = this.delegate.read()) != null;) {
      String prefix = line.readString(0);
      if (prefix.equals("HEA")) {
        t = new Trade(); // Record must start with header
      }
      else if (prefix.equals("NCU")) {
        Assert.notNull(t, "No header was found.");
        t.setLast(line.readString(1));
        t.setFirst(line.readString(2));
        ...
      }
      else if (prefix.equals("BAD")) {
        Assert.notNull(t, "No header was found.");
        t.setCity(line.readString(4));
        t.setState(line.readString(6));
        ...
      }
      else if (prefix.equals("FOT")) {
        return t; // Record must end with footer
      }
    }
    Assert.isNull(t, "No 'END' was found.");
    return null;
  }</programlisting>
  </section>

  <section>
    <title>Executing System Commands</title>

    <para>Many batch jobs may require that an external command be called from
    within the batch job. Such a process could be kicked off separately by the
    scheduler, but the advantage of common meta-data about the run would be
    lost. Furthermore, a multi-step job would also need to be split up into
    multiple jobs as well.</para>

    <para>Because the need is so common, Spring Batch provides a
    <classname>Tasklet</classname> implementation for calling system
    commands:</para>

    <programlisting>  &lt;bean class="org.springframework.batch.sample.tasklet.SystemCommandTasklet"&gt;
    &lt;property name="command" value="echo hello" /&gt;
    &lt;!-- 5 second timeout for the command to complete --&gt;
    &lt;property name="timeout" value="5000" /&gt;
  &lt;/bean&gt;</programlisting>
  </section>
</chapter>
